{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erez-meoded/TrOCR-HTR/blob/master/paper_training_with_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUTVEcSZBa3y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "GUTVEcSZBa3y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TFEYLlK4Wti"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers evaluate jiwer datasets accelerate"
      ],
      "id": "9TFEYLlK4Wti"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8e9ef2e"
      },
      "outputs": [],
      "source": [
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from transformers import default_data_collator\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image, ImageFilter\n",
        "from pickle import load, dump\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import evaluate\n",
        "import torch\n",
        "import os\n",
        "from torchvision.transforms import Resize, RandomChoice, Compose, Grayscale, GaussianBlur, ElasticTransform,RandomPerspective, RandomRotation, RandomAffine"
      ],
      "id": "e8e9ef2e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV8z4aw_4SC5"
      },
      "outputs": [],
      "source": [
        "!unzip -qq \"/content/drive/MyDrive/Theses/Data/Historical/paper.zip\""
      ],
      "id": "JV8z4aw_4SC5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4MDHvtoZyvc"
      },
      "outputs": [],
      "source": [
        "df_train, df_val = tts(load(open('/content/drive/MyDrive/Theses/Data/Historical/df.pkl', 'rb')),test_size=0.2,random_state=81,shuffle=True)\n",
        "df_train.reset_index(drop=True,inplace=True)\n",
        "df_val.reset_index(drop=True,inplace=True)\n",
        "df_val, df_test = tts(df_val,test_size=0.5,random_state=81,shuffle=True)\n",
        "df_val.reset_index(drop=True,inplace=True)\n",
        "df_test.reset_index(drop=True,inplace=True)\n",
        "df_train.shape,df_val.shape,df_test.shape"
      ],
      "id": "r4MDHvtoZyvc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd965253"
      },
      "source": [
        "## Prepare the Gwalther data"
      ],
      "id": "dd965253"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2fc1762"
      },
      "outputs": [],
      "source": [
        "# set up dataset class\n",
        "class GwaltherDataset(Dataset):\n",
        "    def __init__(self, root_dir, df, processor, max_target_length=128, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.max_target_length = max_target_length\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get file name + text\n",
        "        file_name = self.df['file_name'][idx]\n",
        "        text = self.df['text'][idx]\n",
        "        # prepare image (i.e. resize + normalize)\n",
        "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "          image = transform(image)\n",
        "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
        "        # add labels (input_ids) by encoding the text\n",
        "        labels = self.processor.tokenizer(text,\n",
        "                                          padding=\"max_length\",\n",
        "                                          max_length=self.max_target_length).input_ids\n",
        "        # important: make sure that PAD tokens are ignored by the loss function\n",
        "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
        "\n",
        "        encoding = {\"file\": file_name, \"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
        "        return encoding"
      ],
      "id": "b2fc1762"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMKQfEMYoHeE"
      },
      "source": [
        "## Augmentation"
      ],
      "id": "OMKQfEMYoHeE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afp1xCK-_sWy"
      },
      "outputs": [],
      "source": [
        "class InterpolationMode():\n",
        "    NEAREST = 0\n",
        "    BILINEAR = 2\n",
        "    BICUBIC = 3\n",
        "    BOX = 4\n",
        "    HAMMING = 5\n",
        "    LANCZOS = 1\n",
        "\n",
        "class Dilation(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, kernel=3):\n",
        "        super().__init__()\n",
        "        self.kernel=kernel\n",
        "\n",
        "    def forward(self, img):\n",
        "        return img.filter(ImageFilter.MaxFilter(self.kernel))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(kernel={})'.format(self.kernel)\n",
        "\n",
        "class Erosion(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, kernel=3):\n",
        "        super().__init__()\n",
        "        self.kernel=kernel\n",
        "\n",
        "    def forward(self, img):\n",
        "        return img.filter(ImageFilter.MinFilter(self.kernel))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(kernel={})'.format(self.kernel)\n",
        "\n",
        "class Underline(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_cp = deepcopy(img)\n",
        "        img_np = np.array(img_cp.convert('L'))\n",
        "        black_pixels = np.where(img_np < 50)\n",
        "        try:\n",
        "            y1 = max(black_pixels[0])\n",
        "            x0 = min(black_pixels[1])\n",
        "            x1 = max(black_pixels[1])\n",
        "        except:\n",
        "            return img\n",
        "        for x in range(x0, x1):\n",
        "            for y in range(y1, y1-3, -1):\n",
        "                try:\n",
        "                    #img.putpixel((x, y), (0, 0, 0)) #original from MS with a bug. This is an 'L' mode (grayscale) and cannot have 3 channels\n",
        "                    img_cp.putpixel((x, y), 0)\n",
        "                except:\n",
        "                    continue\n",
        "        return img_cp\n",
        "\n",
        "class KeepOriginal(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, img):\n",
        "        return img\n",
        "\n",
        "class ReResize(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, kernel=3):\n",
        "        super().__init__()\n",
        "        self.kernel=kernel\n",
        "\n",
        "    def forward(self, img):\n",
        "        return ImgResize(1/self.kernel)(ImgResize(self.kernel)(img))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(kernel={})'.format(self.kernel)\n",
        "\n",
        "class ImgResize(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, kernel=3):\n",
        "        super().__init__()\n",
        "        self.kernel=kernel\n",
        "\n",
        "    def forward(self, img):\n",
        "        size = np.flip(np.array(img.size))\n",
        "        return Resize((int(size[0]/self.kernel), int(size[1]/self.kernel)), interpolation=InterpolationMode.NEAREST)(img)\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(kernel={})'.format(self.kernel)\n"
      ],
      "id": "Afp1xCK-_sWy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGgxDHm-oLMc"
      },
      "outputs": [],
      "source": [
        "rotation = RandomRotation(degrees=(-10, 10), expand=True, fill=255)\n",
        "gaussianblur = GaussianBlur(3)\n",
        "dilation = Dilation()\n",
        "erosion = Erosion()\n",
        "resize = ImgResize()\n",
        "underline = Underline()\n",
        "baseline = KeepOriginal()\n",
        "\n",
        "affine = RandomAffine(degrees=2.5, translate=(0,.250), shear=50, scale=(.5,1), fill=255)\n",
        "perspective = RandomPerspective(p=1,fill=255)\n",
        "elastic = ElasticTransform(alpha=10.0, sigma=5.,fill=255)\n",
        "re_resize = ReResize()\n",
        "\n",
        "transforms_dict = {\n",
        "    # \"BASELINE\":baseline,\n",
        "    # \"RANDOM_ROTATION\": rotation,\n",
        "    # \"GAUSSIAN_BLUR\": gaussianblur,\n",
        "    # \"DILATION\": dilation,\n",
        "    # \"EROSION\": erosion,\n",
        "    # \"RESIZE\": resize,\n",
        "    # \"UNDERLINE\": underline,\n",
        "\n",
        "    # \"RANDOM_AFFINE\": affine,\n",
        "    \"RANDOM_PERSPECTIVE\": perspective,\n",
        "    \"ELASTIC\": elastic,\n",
        "    \"RE_RESIZE\": re_resize\n",
        "}"
      ],
      "id": "LGgxDHm-oLMc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "882b39d1"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "Or rather, fine-tune\n"
      ],
      "id": "882b39d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "389ffa79"
      },
      "outputs": [],
      "source": [
        "def get_model(model='microsoft/trocr-base-handwritten'):\n",
        "  model = VisionEncoderDecoderModel.from_pretrained(model)\n",
        "  # set special tokens used for creating the decoder_input_ids from the labels\n",
        "  model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
        "  model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
        "  # make sure vocab size is set correctly\n",
        "  model.config.vocab_size = model.config.decoder.vocab_size\n",
        "\n",
        "  # set to make it trainable:\n",
        "  model.config.decoder.is_decoder = True\n",
        "  model.config.decoder.add_cross_attention = True\n",
        "\n",
        "  # set beam search parameters\n",
        "  model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
        "  model.config.max_length = 64\n",
        "  model.config.early_stopping = True\n",
        "  model.config.no_repeat_ngram_size = 3\n",
        "  model.config.length_penalty = 2.0\n",
        "  model.config.num_beams = 4\n",
        "  return model"
      ],
      "id": "389ffa79"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy8fwKugrbym"
      },
      "outputs": [],
      "source": [
        "root=\"/content/drive/MyDrive/Theses/Experiments/Historical/\""
      ],
      "id": "zy8fwKugrbym"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWB5U7Mr9YeQ"
      },
      "outputs": [],
      "source": [
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "    print(pred_str)\n",
        "    print(label_str)\n",
        "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"cer\": cer}\n"
      ],
      "id": "BWB5U7Mr9YeQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00c6cd80"
      },
      "outputs": [],
      "source": [
        "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')"
      ],
      "id": "00c6cd80"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR7zRHJ0rsxN"
      },
      "outputs": [],
      "source": [
        "for experiment, transform in transforms_dict.items():\n",
        "  print(experiment)\n",
        "\n",
        "  model = get_model()\n",
        "  path = root + experiment\n",
        "\n",
        "  if not os.path.isdir(path):\n",
        "    !mkdir {path}\n",
        "  os.chdir(path)\n",
        "\n",
        "  train_dataset = GwaltherDataset(root_dir='/content/paper/', df=df_train, processor=processor, transform=RandomChoice([transform,baseline]))\n",
        "  eval_dataset  = GwaltherDataset(root_dir='/content/paper/', df=df_val,   processor=processor, transform=None)\n",
        "  test_dataset  = GwaltherDataset(root_dir='/content/paper/', df=df_test,   processor=processor, transform=None)\n",
        "\n",
        "  training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate = True,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    load_best_model_at_end = True,\n",
        "    save_total_limit = 1,\n",
        "    per_device_train_batch_size = 8,\n",
        "    per_device_eval_batch_size = 8,\n",
        "    learning_rate = 2e-05,\n",
        "#    warmup_steps = 500,\n",
        "#    weight_decay = 0.0001,\n",
        "#    lr_scheduler_type = \"inverse_sqrt\",\n",
        "\n",
        "    fp16=True,\n",
        "    output_dir=path,\n",
        "#    logging_steps=2,\n",
        "#    save_steps=450,\n",
        "#    eval_steps=450,\n",
        "    num_train_epochs=5,\n",
        "  )\n",
        "\n",
        "  trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=default_data_collator,\n",
        "    # callbacks=[EarlyStoppingCallback(3, 0.0)]\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  eval=trainer.evaluate(test_dataset)\n",
        "  print(eval)"
      ],
      "id": "xR7zRHJ0rsxN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aKqarlDydiy"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "id": "5aKqarlDydiy"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}